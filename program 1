import numpy as np
import pylab as pl
from sklearn import datasets
from sklearn.tree import DecisionTreeRegressor


from sklearn.metrics import mean_absolute_error
from sklearn import datasets
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error,median_absolute_error,r2_score,mean_absolute_error
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split

def load_data():
    boston=datasets.boston()
    return boston
def explore_city_data(city_data):
    housing_prices=city_data.target
    housing_features=city_data.data
    number_of_houses=housing_features.shape[0]
    number_of_features=housing_features.shape[1]
    max_prices=np.max(housing_prices)
    min_prices=np.min(housing_prices)
    mean_prices=np.mean(housing_prices)
    median_prices=np.median(housing_prices)
    standard_deviation=np.std(housing_prices)
    print("number of houses",number_of_houses)
    print("number of features",number_of_features)
    print("max price of house",max_prices)
    print("min of houses",min_prices)
    print("mean of houses",mean_prices)
    print("median of houses",median_prices)
    print("std of house is",standard_deviation)
    
    
    

def Performence_metrics(label,prediction):
    return mean_squared_error(label,prediction)
pass

def split_data(city_data):
    x,y=city_data.data,city_data.target
    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,train_size=0.70,random_state=42)
    return x_train,y_train,x_test,y_text

def learning_curve(depth,x_train,y_train,x_test,y_test):
    sizes=np.linespace(1,len(x_train),50)
    